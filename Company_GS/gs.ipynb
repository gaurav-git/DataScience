{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading wget-3.2.zip\n",
      "Building wheels for collected packages: wget\n",
      "  Running setup.py bdist_wheel for wget ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/gauravk/.cache/pip/wheels/6d/98/29/61ccc41148f871009126c2e844e26f73eeb25e12cca92228a5\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a0409a00-8-dataset_dp  gcPredictionFile.csv  gcTrianingSet.csv\tUntitled.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "# wget.download(\"https://cdn.hackerrank.com/contests/gs_quantify_2017/gcPredictionFile.csv\")\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"gcTrianingSet.csv\")\n",
    "test = pd.read_csv(\"gcPredictionFile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2730, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['initialUsedMemory', 'initialFreeMemory', 'query token', 'gcRun',\n",
       "       'gcInitialMemory', 'gcFinalMemory', 'gcTotalMemory', 'userTime',\n",
       "       'sysTime', 'realTime', 'cpuTimeTaken', 'finalUsedMemory',\n",
       "       'finalFreeMemory'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train.shape)\n",
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initialUsedMemory</th>\n",
       "      <th>initialFreeMemory</th>\n",
       "      <th>query token</th>\n",
       "      <th>gcRun</th>\n",
       "      <th>gcInitialMemory</th>\n",
       "      <th>gcFinalMemory</th>\n",
       "      <th>gcTotalMemory</th>\n",
       "      <th>cpuTimeTaken</th>\n",
       "      <th>finalUsedMemory</th>\n",
       "      <th>finalFreeMemory</th>\n",
       "      <th>initialMemoryRatio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.249634</td>\n",
       "      <td>2.999878</td>\n",
       "      <td>token_1</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.371230</td>\n",
       "      <td>4.409714</td>\n",
       "      <td>2.839798</td>\n",
       "      <td>0.705914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.409720</td>\n",
       "      <td>2.839792</td>\n",
       "      <td>token_2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.220883</td>\n",
       "      <td>4.482361</td>\n",
       "      <td>2.767151</td>\n",
       "      <td>0.643985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.482361</td>\n",
       "      <td>2.767151</td>\n",
       "      <td>token_3</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141776</td>\n",
       "      <td>4.542626</td>\n",
       "      <td>2.706886</td>\n",
       "      <td>0.617342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.542626</td>\n",
       "      <td>2.706886</td>\n",
       "      <td>token_4</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156459</td>\n",
       "      <td>4.616293</td>\n",
       "      <td>2.633218</td>\n",
       "      <td>0.595886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.616296</td>\n",
       "      <td>2.633216</td>\n",
       "      <td>token_5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285218</td>\n",
       "      <td>4.787172</td>\n",
       "      <td>2.462339</td>\n",
       "      <td>0.570418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   initialUsedMemory  initialFreeMemory query token  gcRun  gcInitialMemory  \\\n",
       "0           4.249634           2.999878     token_1  False              0.0   \n",
       "1           4.409720           2.839792     token_2  False              0.0   \n",
       "2           4.482361           2.767151     token_3  False              0.0   \n",
       "3           4.542626           2.706886     token_4  False              0.0   \n",
       "4           4.616296           2.633216     token_5  False              0.0   \n",
       "\n",
       "   gcFinalMemory  gcTotalMemory  cpuTimeTaken  finalUsedMemory  \\\n",
       "0            0.0            0.0      0.371230         4.409714   \n",
       "1            0.0            0.0      0.220883         4.482361   \n",
       "2            0.0            0.0      0.141776         4.542626   \n",
       "3            0.0            0.0      0.156459         4.616293   \n",
       "4            0.0            0.0      0.285218         4.787172   \n",
       "\n",
       "   finalFreeMemory  initialMemoryRatio  \n",
       "0         2.839798            0.705914  \n",
       "1         2.767151            0.643985  \n",
       "2         2.706886            0.617342  \n",
       "3         2.633218            0.595886  \n",
       "4         2.462339            0.570418  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"initialMemoryRatio\"] = train[\"initialFreeMemory\"]/train[\"initialUsedMemory\"]\n",
    "# train.drop(train.columns[7], axis=1, inplace=True)\n",
    "# train.drop(train.columns[7], axis=1, inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['token_1', 'token_2', 'token_3', 'token_4', 'token_5', 'token_6',\n",
       "       'token_7', 'token_8', 'token_9', 'token_10', 'token_11', 'token_12',\n",
       "       'token_13', 'token_14', 'token_15', 'token_16', 'token_17',\n",
       "       'token_18', 'token_19', 'token_20', 'token_21', 'token_22',\n",
       "       'token_23', 'token_24', 'token_25', 'token_26', 'token_27',\n",
       "       'token_28', 'token_29', 'token_30', 'token_31', 'token_32',\n",
       "       'token_33', 'token_34', 'token_35', 'token_36', 'token_37',\n",
       "       'token_38', 'token_39', 'token_40', 'token_41', 'token_42',\n",
       "       'token_43', 'token_44', 'token_45', 'token_46', 'token_47',\n",
       "       'token_48', 'token_49', 'token_50', 'token_51', 'token_52',\n",
       "       'token_53', 'token_54', 'token_55', 'token_56', 'token_57',\n",
       "       'token_58', 'token_59', 'token_60', 'token_61', 'token_62',\n",
       "       'token_63', 'token_64', 'token_65', 'token_66', 'token_67',\n",
       "       'token_68', 'token_69', 'token_70', 'token_71', 'token_72',\n",
       "       'token_73', 'token_74', 'token_75', 'token_76', 'token_77',\n",
       "       'token_78', 'token_79', 'token_80', 'token_81', 'token_82',\n",
       "       'token_83', 'token_84', 'token_85', 'token_86', 'token_87',\n",
       "       'token_88', 'token_89', 'token_90', 'token_91'], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = train[train.columns[2]].unique()\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = []\n",
    "n_true = []\n",
    "for i in tokens:\n",
    "    tempdf = train[train[train.columns[2]]==i]\n",
    "    n_true.append(tempdf[tempdf[\"gcRun\"]==True].shape[0])\n",
    "    newdf.append(tempdf[tempdf[\"gcRun\"]==True].initialMemoryRatio.mean())\n",
    "\n",
    "# n_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token_1 2 0.18873890507315105\n",
      "token_2 3 0.09593441894308434\n",
      "token_3 0 nan\n",
      "token_4 3 0.16839041511219513\n",
      "token_5 1 0.09602004232407982\n",
      "token_6 0 nan\n",
      "token_7 1 0.07259591725466188\n",
      "token_8 5 0.18498598823098944\n",
      "token_9 6 0.13855432265576928\n",
      "token_10 2 0.26360096117483706\n",
      "token_11 1 0.19725668282125886\n",
      "token_12 0 nan\n",
      "token_13 2 0.3526264379647339\n",
      "token_14 1 0.09738020129049219\n",
      "token_15 8 0.1756643564554345\n",
      "token_16 0 nan\n",
      "token_17 1 0.06441511288441183\n",
      "token_18 2 0.09968236834894968\n",
      "token_19 3 0.2136834735063158\n",
      "token_20 1 0.14343963417168565\n",
      "token_21 1 0.06023204124769451\n",
      "token_22 1 0.13444927955335853\n",
      "token_23 10 0.22198838522887998\n",
      "token_24 3 0.15438537962426413\n",
      "token_25 0 nan\n",
      "token_26 0 nan\n",
      "token_27 1 0.09702635216593711\n",
      "token_28 1 0.049477155739697486\n",
      "token_29 1 0.05978342084039138\n",
      "token_30 3 0.2487736978185958\n",
      "token_31 2 0.16164588768349752\n",
      "token_32 2 0.0604910164565477\n",
      "token_33 4 0.15257141698777918\n",
      "token_34 0 nan\n",
      "token_35 0 nan\n",
      "token_36 3 0.1431072143717337\n",
      "token_37 1 0.08671175451484918\n",
      "token_38 1 0.10762667715658962\n",
      "token_39 2 0.25453722419193237\n",
      "token_40 3 0.2164997812927337\n",
      "token_41 1 0.10485157468475399\n",
      "token_42 3 0.2609242700930871\n",
      "token_43 1 0.06649822163647788\n",
      "token_44 9 0.23399105993059038\n",
      "token_45 11 0.2745498038038561\n",
      "token_46 0 nan\n",
      "token_47 1 0.10060769209397757\n",
      "token_48 1 0.23897936791509347\n",
      "token_49 3 0.1094268669261207\n",
      "token_50 2 0.15903247031621298\n",
      "token_51 0 nan\n",
      "token_52 0 nan\n",
      "token_53 2 0.21081198672188342\n",
      "token_54 1 0.38250759571587867\n",
      "token_55 1 0.053680058183716205\n",
      "token_56 1 0.07518051949724164\n",
      "token_57 0 nan\n",
      "token_58 7 0.20708113152558916\n",
      "token_59 0 nan\n",
      "token_60 0 nan\n",
      "token_61 1 0.07470757387588459\n",
      "token_62 2 0.2746163022205967\n",
      "token_63 5 0.30593200118015207\n",
      "token_64 0 nan\n",
      "token_65 1 0.44754025716212853\n",
      "token_66 0 nan\n",
      "token_67 6 0.20353975681794967\n",
      "token_68 0 nan\n",
      "token_69 4 0.11364679348356384\n",
      "token_70 4 0.2080894049024653\n",
      "token_71 0 nan\n",
      "token_72 0 nan\n",
      "token_73 3 0.06251937630705653\n",
      "token_74 2 0.11909992690830709\n",
      "token_75 1 0.2374449843119914\n",
      "token_76 1 0.18292580521125804\n",
      "token_77 0 nan\n",
      "token_78 1 0.2777137148249676\n",
      "token_79 0 nan\n",
      "token_80 0 nan\n",
      "token_81 1 0.10748511492507487\n",
      "token_82 4 0.25161428523851054\n",
      "token_83 0 nan\n",
      "token_84 2 0.20647522326404816\n",
      "token_85 1 0.2145662547774841\n",
      "token_86 3 0.14787485758755667\n",
      "token_87 3 0.16329923856747916\n",
      "token_88 0 nan\n",
      "token_89 1 0.1004278148909531\n",
      "token_90 0 nan\n",
      "token_91 0 nan\n"
     ]
    }
   ],
   "source": [
    "for i, j, k in zip(tokens, n_true, newdf):\n",
    "    print(i, j, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = pd.DataFrame({\"token\":tokens, \"n_true\":n_true, \"meanRatio\":newdf})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf.fillna(value=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>meanRatio</th>\n",
       "      <th>n_true</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>token_46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>token_34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>token_35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>token_90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>token_51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>51</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>token_52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>56</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>token_57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>58</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>token_59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>59</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>token_60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>token_26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>63</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>token_64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>67</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>token_68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>70</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>token_71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>71</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>token_72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>76</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>token_77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>78</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>token_79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>79</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>token_80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>82</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>token_83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>87</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>token_88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>65</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>token_66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>24</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>token_25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>90</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>token_91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>token_3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>token_12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>token_16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>token_6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.049477</td>\n",
       "      <td>1</td>\n",
       "      <td>token_28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>54</td>\n",
       "      <td>0.053680</td>\n",
       "      <td>1</td>\n",
       "      <td>token_55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.059783</td>\n",
       "      <td>1</td>\n",
       "      <td>token_29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20</td>\n",
       "      <td>0.060232</td>\n",
       "      <td>1</td>\n",
       "      <td>token_21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>3</td>\n",
       "      <td>0.168390</td>\n",
       "      <td>3</td>\n",
       "      <td>token_4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>14</td>\n",
       "      <td>0.175664</td>\n",
       "      <td>8</td>\n",
       "      <td>token_15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>75</td>\n",
       "      <td>0.182926</td>\n",
       "      <td>1</td>\n",
       "      <td>token_76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>7</td>\n",
       "      <td>0.184986</td>\n",
       "      <td>5</td>\n",
       "      <td>token_8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0</td>\n",
       "      <td>0.188739</td>\n",
       "      <td>2</td>\n",
       "      <td>token_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>10</td>\n",
       "      <td>0.197257</td>\n",
       "      <td>1</td>\n",
       "      <td>token_11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>66</td>\n",
       "      <td>0.203540</td>\n",
       "      <td>6</td>\n",
       "      <td>token_67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>83</td>\n",
       "      <td>0.206475</td>\n",
       "      <td>2</td>\n",
       "      <td>token_84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>57</td>\n",
       "      <td>0.207081</td>\n",
       "      <td>7</td>\n",
       "      <td>token_58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>69</td>\n",
       "      <td>0.208089</td>\n",
       "      <td>4</td>\n",
       "      <td>token_70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>52</td>\n",
       "      <td>0.210812</td>\n",
       "      <td>2</td>\n",
       "      <td>token_53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>18</td>\n",
       "      <td>0.213683</td>\n",
       "      <td>3</td>\n",
       "      <td>token_19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>84</td>\n",
       "      <td>0.214566</td>\n",
       "      <td>1</td>\n",
       "      <td>token_85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>39</td>\n",
       "      <td>0.216500</td>\n",
       "      <td>3</td>\n",
       "      <td>token_40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>22</td>\n",
       "      <td>0.221988</td>\n",
       "      <td>10</td>\n",
       "      <td>token_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>43</td>\n",
       "      <td>0.233991</td>\n",
       "      <td>9</td>\n",
       "      <td>token_44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>74</td>\n",
       "      <td>0.237445</td>\n",
       "      <td>1</td>\n",
       "      <td>token_75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>47</td>\n",
       "      <td>0.238979</td>\n",
       "      <td>1</td>\n",
       "      <td>token_48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>29</td>\n",
       "      <td>0.248774</td>\n",
       "      <td>3</td>\n",
       "      <td>token_30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>81</td>\n",
       "      <td>0.251614</td>\n",
       "      <td>4</td>\n",
       "      <td>token_82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>38</td>\n",
       "      <td>0.254537</td>\n",
       "      <td>2</td>\n",
       "      <td>token_39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>41</td>\n",
       "      <td>0.260924</td>\n",
       "      <td>3</td>\n",
       "      <td>token_42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>9</td>\n",
       "      <td>0.263601</td>\n",
       "      <td>2</td>\n",
       "      <td>token_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>44</td>\n",
       "      <td>0.274550</td>\n",
       "      <td>11</td>\n",
       "      <td>token_45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>61</td>\n",
       "      <td>0.274616</td>\n",
       "      <td>2</td>\n",
       "      <td>token_62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>77</td>\n",
       "      <td>0.277714</td>\n",
       "      <td>1</td>\n",
       "      <td>token_78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>62</td>\n",
       "      <td>0.305932</td>\n",
       "      <td>5</td>\n",
       "      <td>token_63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>12</td>\n",
       "      <td>0.352626</td>\n",
       "      <td>2</td>\n",
       "      <td>token_13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>53</td>\n",
       "      <td>0.382508</td>\n",
       "      <td>1</td>\n",
       "      <td>token_54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>64</td>\n",
       "      <td>0.447540</td>\n",
       "      <td>1</td>\n",
       "      <td>token_65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index  meanRatio  n_true     token\n",
       "0      45   0.000000       0  token_46\n",
       "1      33   0.000000       0  token_34\n",
       "2      34   0.000000       0  token_35\n",
       "3      89   0.000000       0  token_90\n",
       "4      50   0.000000       0  token_51\n",
       "5      51   0.000000       0  token_52\n",
       "6      56   0.000000       0  token_57\n",
       "7      58   0.000000       0  token_59\n",
       "8      59   0.000000       0  token_60\n",
       "9      25   0.000000       0  token_26\n",
       "10     63   0.000000       0  token_64\n",
       "11     67   0.000000       0  token_68\n",
       "12     70   0.000000       0  token_71\n",
       "13     71   0.000000       0  token_72\n",
       "14     76   0.000000       0  token_77\n",
       "15     78   0.000000       0  token_79\n",
       "16     79   0.000000       0  token_80\n",
       "17     82   0.000000       0  token_83\n",
       "18     87   0.000000       0  token_88\n",
       "19     65   0.000000       0  token_66\n",
       "20     24   0.000000       0  token_25\n",
       "21     90   0.000000       0  token_91\n",
       "22      2   0.000000       0   token_3\n",
       "23     11   0.000000       0  token_12\n",
       "24     15   0.000000       0  token_16\n",
       "25      5   0.000000       0   token_6\n",
       "26     27   0.049477       1  token_28\n",
       "27     54   0.053680       1  token_55\n",
       "28     28   0.059783       1  token_29\n",
       "29     20   0.060232       1  token_21\n",
       "..    ...        ...     ...       ...\n",
       "61      3   0.168390       3   token_4\n",
       "62     14   0.175664       8  token_15\n",
       "63     75   0.182926       1  token_76\n",
       "64      7   0.184986       5   token_8\n",
       "65      0   0.188739       2   token_1\n",
       "66     10   0.197257       1  token_11\n",
       "67     66   0.203540       6  token_67\n",
       "68     83   0.206475       2  token_84\n",
       "69     57   0.207081       7  token_58\n",
       "70     69   0.208089       4  token_70\n",
       "71     52   0.210812       2  token_53\n",
       "72     18   0.213683       3  token_19\n",
       "73     84   0.214566       1  token_85\n",
       "74     39   0.216500       3  token_40\n",
       "75     22   0.221988      10  token_23\n",
       "76     43   0.233991       9  token_44\n",
       "77     74   0.237445       1  token_75\n",
       "78     47   0.238979       1  token_48\n",
       "79     29   0.248774       3  token_30\n",
       "80     81   0.251614       4  token_82\n",
       "81     38   0.254537       2  token_39\n",
       "82     41   0.260924       3  token_42\n",
       "83      9   0.263601       2  token_10\n",
       "84     44   0.274550      11  token_45\n",
       "85     61   0.274616       2  token_62\n",
       "86     77   0.277714       1  token_78\n",
       "87     62   0.305932       5  token_63\n",
       "88     12   0.352626       2  token_13\n",
       "89     53   0.382508       1  token_54\n",
       "90     64   0.447540       1  token_65\n",
       "\n",
       "[91 rows x 4 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf.sort_values(\"meanRatio\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18873890507315105"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def token_threshold(x):\n",
    "    return newdf[newdf[\"token\"] == x].iloc[0,0]\n",
    "token_threshold(\"token_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train[\"threshold\"] = train[\"query token\"].apply(lambda x: token_threshold(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(train.columns[2], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f43616c0588>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEuCAYAAAB1QVLBAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIHLuQghRQf4/n9ijgbd7qBwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f436176d5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "newdf.sort_values(\"meanRatio\").reset_index().plot(x=\"token\", y=\"meanRatio\", kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(set(train.columns) - set(['gcRun','gcFinalMemory',\n",
    "\n",
    "                                   'gcInitialMemory',\n",
    " 'gcTotalMemory']))\n",
    "y = ['gcRun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['initialFreeMemory',\n",
       " 'finalFreeMemory',\n",
       " 'initialMemoryRatio',\n",
       " 'finalUsedMemory',\n",
       " 'cpuTimeTaken',\n",
       " 'threshold',\n",
       " 'initialUsedMemory']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=2, random_state=42, shuffle=True)\n",
    "skf.get_n_splits(train[X], train[y])\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "New Iteration: \n",
      "\n",
      "Score:  0.997071742313\n",
      "                            0                1                   2  \\\n",
      "col         initialFreeMemory  finalFreeMemory  initialMemoryRatio   \n",
      "importance           0.180013         0.317503            0.136782   \n",
      "\n",
      "                          3             4          5                  6  \n",
      "col         finalUsedMemory  cpuTimeTaken  threshold  initialUsedMemory  \n",
      "importance         0.162341     0.0654047  0.0202179           0.117739  \n",
      "**********\n",
      "New Iteration: \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gauravk/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n",
      "/home/gauravk/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score:  0.995601173021\n",
      "                            0                1                   2  \\\n",
      "col         initialFreeMemory  finalFreeMemory  initialMemoryRatio   \n",
      "importance           0.224575         0.272714           0.0585762   \n",
      "\n",
      "                          3             4          5                  6  \n",
      "col         finalUsedMemory  cpuTimeTaken  threshold  initialUsedMemory  \n",
      "importance         0.146896     0.0529222  0.0414429           0.202874  \n"
     ]
    }
   ],
   "source": [
    "data = train[X]\n",
    "op = train[y]\n",
    "for train_index, test_index in skf.split(data, op.values.reshape((op.shape[0],))):\n",
    "    print(\"*\"*10)\n",
    "    print(\"New Iteration: \\n\")\n",
    "    X_train, X_test = data.iloc[train_index], data.iloc[test_index]\n",
    "    y_train, y_test = op.iloc[train_index], op.iloc[test_index]\n",
    "    rfc.fit(X_train, y_train)\n",
    "    print(\"Score: \", accuracy_score(rfc.predict(X_test), y_test))\n",
    "    temp = pd.DataFrame({'col':data.columns, 'importance':rfc.feature_importances_})\n",
    "    print(temp.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train[X], train[y].values, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1911, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gauravk/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "intc = 0\n",
    "for i in y_test:\n",
    "    if i==True:\n",
    "        intc+=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    2559\n",
       "True      171\n",
       "Name: gcRun, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[y][\"gcRun\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99511599511599513"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(rfc.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        ,  0.27957075,  0.        ,  0.02042925,  0.        ,\n",
       "        0.        ,  0.4       ,  0.3       ,  0.        ,  0.        ])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['initialFreeMemory', 'gcFinalMemory', 'initialMemoryRatio',\n",
       "       'finalUsedMemory', 'initialUsedMemory', 'finalFreeMemory',\n",
       "       'gcInitialMemory', 'gcTotalMemory', 'cpuTimeTaken', 'threshold'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[X].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[umns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>initialUsedMemory</th>\n",
       "      <th>initialFreeMemory</th>\n",
       "      <th>finalUsedMemory</th>\n",
       "      <th>finalFreeMemory</th>\n",
       "      <th>gcRun</th>\n",
       "      <th>gcInitialMemory</th>\n",
       "      <th>gcFinalMemory</th>\n",
       "      <th>gcTotalMemory</th>\n",
       "      <th>cpuTimeTaken</th>\n",
       "      <th>initialMemoryRatio</th>\n",
       "      <th>threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.249634</td>\n",
       "      <td>2.999878</td>\n",
       "      <td>4.409714</td>\n",
       "      <td>2.839798</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.371230</td>\n",
       "      <td>0.705914</td>\n",
       "      <td>0.188739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.409720</td>\n",
       "      <td>2.839792</td>\n",
       "      <td>4.482361</td>\n",
       "      <td>2.767151</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.220883</td>\n",
       "      <td>0.643985</td>\n",
       "      <td>0.095934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.482361</td>\n",
       "      <td>2.767151</td>\n",
       "      <td>4.542626</td>\n",
       "      <td>2.706886</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141776</td>\n",
       "      <td>0.617342</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.542626</td>\n",
       "      <td>2.706886</td>\n",
       "      <td>4.616293</td>\n",
       "      <td>2.633218</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156459</td>\n",
       "      <td>0.595886</td>\n",
       "      <td>0.168390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.616296</td>\n",
       "      <td>2.633216</td>\n",
       "      <td>4.787172</td>\n",
       "      <td>2.462339</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285218</td>\n",
       "      <td>0.570418</td>\n",
       "      <td>0.096020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.787174</td>\n",
       "      <td>2.462337</td>\n",
       "      <td>4.902623</td>\n",
       "      <td>2.346889</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170063</td>\n",
       "      <td>0.514361</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.902623</td>\n",
       "      <td>2.346889</td>\n",
       "      <td>4.977153</td>\n",
       "      <td>2.272359</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.164785</td>\n",
       "      <td>0.478701</td>\n",
       "      <td>0.072596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.977155</td>\n",
       "      <td>2.272357</td>\n",
       "      <td>4.168083</td>\n",
       "      <td>3.081428</td>\n",
       "      <td>True</td>\n",
       "      <td>5.055250</td>\n",
       "      <td>4.142316</td>\n",
       "      <td>7.249512</td>\n",
       "      <td>0.154474</td>\n",
       "      <td>0.456557</td>\n",
       "      <td>0.184986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.171586</td>\n",
       "      <td>3.077926</td>\n",
       "      <td>4.520573</td>\n",
       "      <td>2.728938</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.457611</td>\n",
       "      <td>0.737831</td>\n",
       "      <td>0.138554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.523625</td>\n",
       "      <td>2.725887</td>\n",
       "      <td>4.621179</td>\n",
       "      <td>2.628333</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.182251</td>\n",
       "      <td>0.602589</td>\n",
       "      <td>0.263601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.621179</td>\n",
       "      <td>2.628333</td>\n",
       "      <td>4.720848</td>\n",
       "      <td>2.528664</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190840</td>\n",
       "      <td>0.568758</td>\n",
       "      <td>0.197257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.720848</td>\n",
       "      <td>2.528664</td>\n",
       "      <td>4.861294</td>\n",
       "      <td>2.388217</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207480</td>\n",
       "      <td>0.535638</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.861294</td>\n",
       "      <td>2.388217</td>\n",
       "      <td>4.919907</td>\n",
       "      <td>2.329605</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.121614</td>\n",
       "      <td>0.491272</td>\n",
       "      <td>0.352626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.919907</td>\n",
       "      <td>2.329605</td>\n",
       "      <td>5.050119</td>\n",
       "      <td>2.199393</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.227620</td>\n",
       "      <td>0.473506</td>\n",
       "      <td>0.097380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.050119</td>\n",
       "      <td>2.199393</td>\n",
       "      <td>4.239779</td>\n",
       "      <td>3.009732</td>\n",
       "      <td>True</td>\n",
       "      <td>5.120831</td>\n",
       "      <td>4.137337</td>\n",
       "      <td>7.249512</td>\n",
       "      <td>0.275411</td>\n",
       "      <td>0.435513</td>\n",
       "      <td>0.175664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.243753</td>\n",
       "      <td>3.005758</td>\n",
       "      <td>4.277324</td>\n",
       "      <td>2.972188</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.708278</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4.280944</td>\n",
       "      <td>2.968567</td>\n",
       "      <td>4.462195</td>\n",
       "      <td>2.787316</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.239481</td>\n",
       "      <td>0.693437</td>\n",
       "      <td>0.064415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.462195</td>\n",
       "      <td>2.787316</td>\n",
       "      <td>4.582409</td>\n",
       "      <td>2.667103</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173965</td>\n",
       "      <td>0.624651</td>\n",
       "      <td>0.099682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.582409</td>\n",
       "      <td>2.667103</td>\n",
       "      <td>4.750459</td>\n",
       "      <td>2.499053</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252222</td>\n",
       "      <td>0.582031</td>\n",
       "      <td>0.213683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.750459</td>\n",
       "      <td>2.499053</td>\n",
       "      <td>4.907353</td>\n",
       "      <td>2.342159</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197709</td>\n",
       "      <td>0.526066</td>\n",
       "      <td>0.143440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.907353</td>\n",
       "      <td>2.342159</td>\n",
       "      <td>4.995290</td>\n",
       "      <td>2.254222</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.206092</td>\n",
       "      <td>0.477275</td>\n",
       "      <td>0.060232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4.995290</td>\n",
       "      <td>2.254222</td>\n",
       "      <td>5.045302</td>\n",
       "      <td>2.204210</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096779</td>\n",
       "      <td>0.451269</td>\n",
       "      <td>0.134449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.045302</td>\n",
       "      <td>2.204210</td>\n",
       "      <td>4.656779</td>\n",
       "      <td>2.592733</td>\n",
       "      <td>True</td>\n",
       "      <td>5.115852</td>\n",
       "      <td>4.132132</td>\n",
       "      <td>7.249512</td>\n",
       "      <td>0.592555</td>\n",
       "      <td>0.436884</td>\n",
       "      <td>0.221988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.662953</td>\n",
       "      <td>2.586559</td>\n",
       "      <td>4.789210</td>\n",
       "      <td>2.460302</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216461</td>\n",
       "      <td>0.554704</td>\n",
       "      <td>0.154385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4.792982</td>\n",
       "      <td>2.456530</td>\n",
       "      <td>4.842613</td>\n",
       "      <td>2.406899</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086305</td>\n",
       "      <td>0.512526</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4.842718</td>\n",
       "      <td>2.406794</td>\n",
       "      <td>4.858456</td>\n",
       "      <td>2.391055</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026951</td>\n",
       "      <td>0.496992</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4.858725</td>\n",
       "      <td>2.390786</td>\n",
       "      <td>4.911962</td>\n",
       "      <td>2.337550</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100673</td>\n",
       "      <td>0.492060</td>\n",
       "      <td>0.097026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.911962</td>\n",
       "      <td>2.337550</td>\n",
       "      <td>5.001542</td>\n",
       "      <td>2.247970</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.171593</td>\n",
       "      <td>0.475889</td>\n",
       "      <td>0.049477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.001671</td>\n",
       "      <td>2.247841</td>\n",
       "      <td>5.065997</td>\n",
       "      <td>2.183514</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123160</td>\n",
       "      <td>0.449418</td>\n",
       "      <td>0.059783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.065997</td>\n",
       "      <td>2.183514</td>\n",
       "      <td>4.149363</td>\n",
       "      <td>3.100148</td>\n",
       "      <td>True</td>\n",
       "      <td>5.110647</td>\n",
       "      <td>4.115836</td>\n",
       "      <td>7.249512</td>\n",
       "      <td>0.119891</td>\n",
       "      <td>0.431014</td>\n",
       "      <td>0.248774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2700</th>\n",
       "      <td>5.371504</td>\n",
       "      <td>2.235430</td>\n",
       "      <td>5.409899</td>\n",
       "      <td>2.197035</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081003</td>\n",
       "      <td>0.416165</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2701</th>\n",
       "      <td>5.409899</td>\n",
       "      <td>2.197035</td>\n",
       "      <td>5.471979</td>\n",
       "      <td>2.134955</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.119174</td>\n",
       "      <td>0.406114</td>\n",
       "      <td>0.163299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2702</th>\n",
       "      <td>5.471979</td>\n",
       "      <td>2.134955</td>\n",
       "      <td>5.567664</td>\n",
       "      <td>2.039270</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181636</td>\n",
       "      <td>0.390161</td>\n",
       "      <td>0.263601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>5.567664</td>\n",
       "      <td>2.039270</td>\n",
       "      <td>5.644413</td>\n",
       "      <td>1.962521</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144991</td>\n",
       "      <td>0.366270</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>5.644413</td>\n",
       "      <td>1.962521</td>\n",
       "      <td>5.721961</td>\n",
       "      <td>1.884973</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139357</td>\n",
       "      <td>0.347693</td>\n",
       "      <td>0.251614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>5.721961</td>\n",
       "      <td>1.884973</td>\n",
       "      <td>5.875133</td>\n",
       "      <td>1.731801</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242884</td>\n",
       "      <td>0.329428</td>\n",
       "      <td>0.096020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>5.875133</td>\n",
       "      <td>1.731801</td>\n",
       "      <td>6.475813</td>\n",
       "      <td>1.131120</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.588336</td>\n",
       "      <td>0.294768</td>\n",
       "      <td>0.221988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>6.475813</td>\n",
       "      <td>1.131120</td>\n",
       "      <td>6.601231</td>\n",
       "      <td>1.005703</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177075</td>\n",
       "      <td>0.174668</td>\n",
       "      <td>0.099682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2708</th>\n",
       "      <td>6.601231</td>\n",
       "      <td>1.005703</td>\n",
       "      <td>6.658725</td>\n",
       "      <td>0.948209</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106106</td>\n",
       "      <td>0.152351</td>\n",
       "      <td>0.104852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2709</th>\n",
       "      <td>6.658725</td>\n",
       "      <td>0.948209</td>\n",
       "      <td>6.722698</td>\n",
       "      <td>0.884236</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.135733</td>\n",
       "      <td>0.142401</td>\n",
       "      <td>0.072596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2710</th>\n",
       "      <td>6.722698</td>\n",
       "      <td>0.884236</td>\n",
       "      <td>6.784749</td>\n",
       "      <td>0.822184</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.127899</td>\n",
       "      <td>0.131530</td>\n",
       "      <td>0.238979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2711</th>\n",
       "      <td>6.784749</td>\n",
       "      <td>0.822184</td>\n",
       "      <td>6.962422</td>\n",
       "      <td>0.644512</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.273149</td>\n",
       "      <td>0.121181</td>\n",
       "      <td>0.175664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2712</th>\n",
       "      <td>6.962422</td>\n",
       "      <td>0.644512</td>\n",
       "      <td>7.080855</td>\n",
       "      <td>0.526078</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.195532</td>\n",
       "      <td>0.092570</td>\n",
       "      <td>0.075181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>7.080857</td>\n",
       "      <td>0.526076</td>\n",
       "      <td>7.145726</td>\n",
       "      <td>0.461208</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111754</td>\n",
       "      <td>0.074296</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714</th>\n",
       "      <td>7.145726</td>\n",
       "      <td>0.461208</td>\n",
       "      <td>7.200549</td>\n",
       "      <td>0.406384</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117925</td>\n",
       "      <td>0.064543</td>\n",
       "      <td>0.447540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>7.200549</td>\n",
       "      <td>0.406384</td>\n",
       "      <td>5.148405</td>\n",
       "      <td>2.546419</td>\n",
       "      <td>True</td>\n",
       "      <td>7.299377</td>\n",
       "      <td>5.068325</td>\n",
       "      <td>7.694824</td>\n",
       "      <td>0.259157</td>\n",
       "      <td>0.056438</td>\n",
       "      <td>0.213683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>5.162250</td>\n",
       "      <td>2.532574</td>\n",
       "      <td>5.300746</td>\n",
       "      <td>2.394079</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225001</td>\n",
       "      <td>0.490595</td>\n",
       "      <td>0.109427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2717</th>\n",
       "      <td>5.314320</td>\n",
       "      <td>2.380504</td>\n",
       "      <td>5.395838</td>\n",
       "      <td>2.298986</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125304</td>\n",
       "      <td>0.447941</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2718</th>\n",
       "      <td>5.395867</td>\n",
       "      <td>2.298957</td>\n",
       "      <td>5.475984</td>\n",
       "      <td>2.218840</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146119</td>\n",
       "      <td>0.426059</td>\n",
       "      <td>0.237445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2719</th>\n",
       "      <td>5.475984</td>\n",
       "      <td>2.218840</td>\n",
       "      <td>5.891383</td>\n",
       "      <td>1.803442</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.476469</td>\n",
       "      <td>0.405195</td>\n",
       "      <td>0.203540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2720</th>\n",
       "      <td>5.891383</td>\n",
       "      <td>1.803442</td>\n",
       "      <td>6.085278</td>\n",
       "      <td>1.609547</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.245653</td>\n",
       "      <td>0.306115</td>\n",
       "      <td>0.305932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2721</th>\n",
       "      <td>6.085278</td>\n",
       "      <td>1.609547</td>\n",
       "      <td>6.275798</td>\n",
       "      <td>1.419027</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.270267</td>\n",
       "      <td>0.264498</td>\n",
       "      <td>0.100428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2722</th>\n",
       "      <td>6.275798</td>\n",
       "      <td>1.419027</td>\n",
       "      <td>6.339934</td>\n",
       "      <td>1.354890</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130559</td>\n",
       "      <td>0.226111</td>\n",
       "      <td>0.100608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2723</th>\n",
       "      <td>6.339934</td>\n",
       "      <td>1.354890</td>\n",
       "      <td>6.409213</td>\n",
       "      <td>1.285612</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144823</td>\n",
       "      <td>0.213707</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>6.409213</td>\n",
       "      <td>1.285612</td>\n",
       "      <td>6.463606</td>\n",
       "      <td>1.231218</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111179</td>\n",
       "      <td>0.200588</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>6.463606</td>\n",
       "      <td>1.231218</td>\n",
       "      <td>6.594545</td>\n",
       "      <td>1.100279</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.239648</td>\n",
       "      <td>0.190485</td>\n",
       "      <td>0.107627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726</th>\n",
       "      <td>6.594548</td>\n",
       "      <td>1.100277</td>\n",
       "      <td>6.663855</td>\n",
       "      <td>1.030969</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.117739</td>\n",
       "      <td>0.166846</td>\n",
       "      <td>0.095934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2727</th>\n",
       "      <td>6.663855</td>\n",
       "      <td>1.030969</td>\n",
       "      <td>6.727963</td>\n",
       "      <td>0.966862</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109347</td>\n",
       "      <td>0.154711</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2728</th>\n",
       "      <td>6.727963</td>\n",
       "      <td>0.966862</td>\n",
       "      <td>7.036368</td>\n",
       "      <td>0.658456</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.371938</td>\n",
       "      <td>0.143708</td>\n",
       "      <td>0.260924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2729</th>\n",
       "      <td>7.036368</td>\n",
       "      <td>0.658456</td>\n",
       "      <td>7.104307</td>\n",
       "      <td>0.590517</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.115548</td>\n",
       "      <td>0.093579</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2730 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      initialUsedMemory  initialFreeMemory  finalUsedMemory  finalFreeMemory  \\\n",
       "0              4.249634           2.999878         4.409714         2.839798   \n",
       "1              4.409720           2.839792         4.482361         2.767151   \n",
       "2              4.482361           2.767151         4.542626         2.706886   \n",
       "3              4.542626           2.706886         4.616293         2.633218   \n",
       "4              4.616296           2.633216         4.787172         2.462339   \n",
       "5              4.787174           2.462337         4.902623         2.346889   \n",
       "6              4.902623           2.346889         4.977153         2.272359   \n",
       "7              4.977155           2.272357         4.168083         3.081428   \n",
       "8              4.171586           3.077926         4.520573         2.728938   \n",
       "9              4.523625           2.725887         4.621179         2.628333   \n",
       "10             4.621179           2.628333         4.720848         2.528664   \n",
       "11             4.720848           2.528664         4.861294         2.388217   \n",
       "12             4.861294           2.388217         4.919907         2.329605   \n",
       "13             4.919907           2.329605         5.050119         2.199393   \n",
       "14             5.050119           2.199393         4.239779         3.009732   \n",
       "15             4.243753           3.005758         4.277324         2.972188   \n",
       "16             4.280944           2.968567         4.462195         2.787316   \n",
       "17             4.462195           2.787316         4.582409         2.667103   \n",
       "18             4.582409           2.667103         4.750459         2.499053   \n",
       "19             4.750459           2.499053         4.907353         2.342159   \n",
       "20             4.907353           2.342159         4.995290         2.254222   \n",
       "21             4.995290           2.254222         5.045302         2.204210   \n",
       "22             5.045302           2.204210         4.656779         2.592733   \n",
       "23             4.662953           2.586559         4.789210         2.460302   \n",
       "24             4.792982           2.456530         4.842613         2.406899   \n",
       "25             4.842718           2.406794         4.858456         2.391055   \n",
       "26             4.858725           2.390786         4.911962         2.337550   \n",
       "27             4.911962           2.337550         5.001542         2.247970   \n",
       "28             5.001671           2.247841         5.065997         2.183514   \n",
       "29             5.065997           2.183514         4.149363         3.100148   \n",
       "...                 ...                ...              ...              ...   \n",
       "2700           5.371504           2.235430         5.409899         2.197035   \n",
       "2701           5.409899           2.197035         5.471979         2.134955   \n",
       "2702           5.471979           2.134955         5.567664         2.039270   \n",
       "2703           5.567664           2.039270         5.644413         1.962521   \n",
       "2704           5.644413           1.962521         5.721961         1.884973   \n",
       "2705           5.721961           1.884973         5.875133         1.731801   \n",
       "2706           5.875133           1.731801         6.475813         1.131120   \n",
       "2707           6.475813           1.131120         6.601231         1.005703   \n",
       "2708           6.601231           1.005703         6.658725         0.948209   \n",
       "2709           6.658725           0.948209         6.722698         0.884236   \n",
       "2710           6.722698           0.884236         6.784749         0.822184   \n",
       "2711           6.784749           0.822184         6.962422         0.644512   \n",
       "2712           6.962422           0.644512         7.080855         0.526078   \n",
       "2713           7.080857           0.526076         7.145726         0.461208   \n",
       "2714           7.145726           0.461208         7.200549         0.406384   \n",
       "2715           7.200549           0.406384         5.148405         2.546419   \n",
       "2716           5.162250           2.532574         5.300746         2.394079   \n",
       "2717           5.314320           2.380504         5.395838         2.298986   \n",
       "2718           5.395867           2.298957         5.475984         2.218840   \n",
       "2719           5.475984           2.218840         5.891383         1.803442   \n",
       "2720           5.891383           1.803442         6.085278         1.609547   \n",
       "2721           6.085278           1.609547         6.275798         1.419027   \n",
       "2722           6.275798           1.419027         6.339934         1.354890   \n",
       "2723           6.339934           1.354890         6.409213         1.285612   \n",
       "2724           6.409213           1.285612         6.463606         1.231218   \n",
       "2725           6.463606           1.231218         6.594545         1.100279   \n",
       "2726           6.594548           1.100277         6.663855         1.030969   \n",
       "2727           6.663855           1.030969         6.727963         0.966862   \n",
       "2728           6.727963           0.966862         7.036368         0.658456   \n",
       "2729           7.036368           0.658456         7.104307         0.590517   \n",
       "\n",
       "      gcRun  gcInitialMemory  gcFinalMemory  gcTotalMemory  cpuTimeTaken  \\\n",
       "0     False         0.000000       0.000000       0.000000      0.371230   \n",
       "1     False         0.000000       0.000000       0.000000      0.220883   \n",
       "2     False         0.000000       0.000000       0.000000      0.141776   \n",
       "3     False         0.000000       0.000000       0.000000      0.156459   \n",
       "4     False         0.000000       0.000000       0.000000      0.285218   \n",
       "5     False         0.000000       0.000000       0.000000      0.170063   \n",
       "6     False         0.000000       0.000000       0.000000      0.164785   \n",
       "7      True         5.055250       4.142316       7.249512      0.154474   \n",
       "8     False         0.000000       0.000000       0.000000      0.457611   \n",
       "9     False         0.000000       0.000000       0.000000      0.182251   \n",
       "10    False         0.000000       0.000000       0.000000      0.190840   \n",
       "11    False         0.000000       0.000000       0.000000      0.207480   \n",
       "12    False         0.000000       0.000000       0.000000      0.121614   \n",
       "13    False         0.000000       0.000000       0.000000      0.227620   \n",
       "14     True         5.120831       4.137337       7.249512      0.275411   \n",
       "15    False         0.000000       0.000000       0.000000      0.070200   \n",
       "16    False         0.000000       0.000000       0.000000      0.239481   \n",
       "17    False         0.000000       0.000000       0.000000      0.173965   \n",
       "18    False         0.000000       0.000000       0.000000      0.252222   \n",
       "19    False         0.000000       0.000000       0.000000      0.197709   \n",
       "20    False         0.000000       0.000000       0.000000      0.206092   \n",
       "21    False         0.000000       0.000000       0.000000      0.096779   \n",
       "22     True         5.115852       4.132132       7.249512      0.592555   \n",
       "23    False         0.000000       0.000000       0.000000      0.216461   \n",
       "24    False         0.000000       0.000000       0.000000      0.086305   \n",
       "25    False         0.000000       0.000000       0.000000      0.026951   \n",
       "26    False         0.000000       0.000000       0.000000      0.100673   \n",
       "27    False         0.000000       0.000000       0.000000      0.171593   \n",
       "28    False         0.000000       0.000000       0.000000      0.123160   \n",
       "29     True         5.110647       4.115836       7.249512      0.119891   \n",
       "...     ...              ...            ...            ...           ...   \n",
       "2700  False         0.000000       0.000000       0.000000      0.081003   \n",
       "2701  False         0.000000       0.000000       0.000000      0.119174   \n",
       "2702  False         0.000000       0.000000       0.000000      0.181636   \n",
       "2703  False         0.000000       0.000000       0.000000      0.144991   \n",
       "2704  False         0.000000       0.000000       0.000000      0.139357   \n",
       "2705  False         0.000000       0.000000       0.000000      0.242884   \n",
       "2706  False         0.000000       0.000000       0.000000      0.588336   \n",
       "2707  False         0.000000       0.000000       0.000000      0.177075   \n",
       "2708  False         0.000000       0.000000       0.000000      0.106106   \n",
       "2709  False         0.000000       0.000000       0.000000      0.135733   \n",
       "2710  False         0.000000       0.000000       0.000000      0.127899   \n",
       "2711  False         0.000000       0.000000       0.000000      0.273149   \n",
       "2712  False         0.000000       0.000000       0.000000      0.195532   \n",
       "2713  False         0.000000       0.000000       0.000000      0.111754   \n",
       "2714  False         0.000000       0.000000       0.000000      0.117925   \n",
       "2715   True         7.299377       5.068325       7.694824      0.259157   \n",
       "2716  False         0.000000       0.000000       0.000000      0.225001   \n",
       "2717  False         0.000000       0.000000       0.000000      0.125304   \n",
       "2718  False         0.000000       0.000000       0.000000      0.146119   \n",
       "2719  False         0.000000       0.000000       0.000000      0.476469   \n",
       "2720  False         0.000000       0.000000       0.000000      0.245653   \n",
       "2721  False         0.000000       0.000000       0.000000      0.270267   \n",
       "2722  False         0.000000       0.000000       0.000000      0.130559   \n",
       "2723  False         0.000000       0.000000       0.000000      0.144823   \n",
       "2724  False         0.000000       0.000000       0.000000      0.111179   \n",
       "2725  False         0.000000       0.000000       0.000000      0.239648   \n",
       "2726  False         0.000000       0.000000       0.000000      0.117739   \n",
       "2727  False         0.000000       0.000000       0.000000      0.109347   \n",
       "2728  False         0.000000       0.000000       0.000000      0.371938   \n",
       "2729  False         0.000000       0.000000       0.000000      0.115548   \n",
       "\n",
       "      initialMemoryRatio  threshold  \n",
       "0               0.705914   0.188739  \n",
       "1               0.643985   0.095934  \n",
       "2               0.617342   0.000000  \n",
       "3               0.595886   0.168390  \n",
       "4               0.570418   0.096020  \n",
       "5               0.514361   0.000000  \n",
       "6               0.478701   0.072596  \n",
       "7               0.456557   0.184986  \n",
       "8               0.737831   0.138554  \n",
       "9               0.602589   0.263601  \n",
       "10              0.568758   0.197257  \n",
       "11              0.535638   0.000000  \n",
       "12              0.491272   0.352626  \n",
       "13              0.473506   0.097380  \n",
       "14              0.435513   0.175664  \n",
       "15              0.708278   0.000000  \n",
       "16              0.693437   0.064415  \n",
       "17              0.624651   0.099682  \n",
       "18              0.582031   0.213683  \n",
       "19              0.526066   0.143440  \n",
       "20              0.477275   0.060232  \n",
       "21              0.451269   0.134449  \n",
       "22              0.436884   0.221988  \n",
       "23              0.554704   0.154385  \n",
       "24              0.512526   0.000000  \n",
       "25              0.496992   0.000000  \n",
       "26              0.492060   0.097026  \n",
       "27              0.475889   0.049477  \n",
       "28              0.449418   0.059783  \n",
       "29              0.431014   0.248774  \n",
       "...                  ...        ...  \n",
       "2700            0.416165   0.000000  \n",
       "2701            0.406114   0.163299  \n",
       "2702            0.390161   0.263601  \n",
       "2703            0.366270   0.000000  \n",
       "2704            0.347693   0.251614  \n",
       "2705            0.329428   0.096020  \n",
       "2706            0.294768   0.221988  \n",
       "2707            0.174668   0.099682  \n",
       "2708            0.152351   0.104852  \n",
       "2709            0.142401   0.072596  \n",
       "2710            0.131530   0.238979  \n",
       "2711            0.121181   0.175664  \n",
       "2712            0.092570   0.075181  \n",
       "2713            0.074296   0.000000  \n",
       "2714            0.064543   0.447540  \n",
       "2715            0.056438   0.213683  \n",
       "2716            0.490595   0.109427  \n",
       "2717            0.447941   0.000000  \n",
       "2718            0.426059   0.237445  \n",
       "2719            0.405195   0.203540  \n",
       "2720            0.306115   0.305932  \n",
       "2721            0.264498   0.100428  \n",
       "2722            0.226111   0.100608  \n",
       "2723            0.213707   0.000000  \n",
       "2724            0.200588   0.000000  \n",
       "2725            0.190485   0.107627  \n",
       "2726            0.166846   0.095934  \n",
       "2727            0.154711   0.000000  \n",
       "2728            0.143708   0.260924  \n",
       "2729            0.093579   0.000000  \n",
       "\n",
       "[2730 rows x 11 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "umns = ['initialUsedMemory', 'initialFreeMemory',  'finalUsedMemory',\n",
    "       'finalFreeMemory', 'gcRun', 'gcInitialMemory',\n",
    "       'gcFinalMemory', 'gcTotalMemory', 'cpuTimeTaken','initialMemoryRatio', 'threshold']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
